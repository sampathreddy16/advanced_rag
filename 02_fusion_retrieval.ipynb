{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion Retrieval in Document Search\n",
    "\n",
    "## Overview\n",
    "\n",
    "This code implements a Fusion Retrieval system that combines vector-based similarity search with keyword-based BM25 retrieval. The approach aims to leverage the strengths of both methods to improve the overall quality and relevance of document retrieval.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Traditional retrieval methods often rely on either semantic understanding (vector-based) or keyword matching (BM25). Each approach has its strengths and weaknesses. Fusion retrieval aims to combine these methods to create a more robust and accurate retrieval system that can handle a wider range of queries effectively.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. PDF processing and text chunking\n",
    "2. Vector store creation using FAISS and OpenAI embeddings\n",
    "3. BM25 index creation for keyword-based retrieval\n",
    "4. Custom fusion retrieval function that combines both methods\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### Document Preprocessing\n",
    "\n",
    "1. The PDF is loaded and split into chunks using RecursiveCharacterTextSplitter.\n",
    "2. Chunks are cleaned by replacing 't' with spaces (likely addressing a specific formatting issue).\n",
    "\n",
    "### Vector Store Creation\n",
    "\n",
    "1. OpenAI embeddings are used to create vector representations of the text chunks.\n",
    "2. A FAISS vector store is created from these embeddings for efficient similarity search.\n",
    "\n",
    "### BM25 Index Creation\n",
    "\n",
    "1. A BM25 index is created from the same text chunks used for the vector store.\n",
    "2. This allows for keyword-based retrieval alongside the vector-based method.\n",
    "\n",
    "### Fusion Retrieval Function\n",
    "\n",
    "The `fusion_retrieval` function is the core of this implementation:\n",
    "\n",
    "1. It takes a query and performs both vector-based and BM25-based retrieval.\n",
    "2. Scores from both methods are normalized to a common scale.\n",
    "3. A weighted combination of these scores is computed (controlled by the `alpha` parameter).\n",
    "4. Documents are ranked based on the combined scores, and the top-k results are returned.\n",
    "\n",
    "## Benefits of this Approach\n",
    "\n",
    "1. Improved Retrieval Quality: By combining semantic and keyword-based search, the system can capture both conceptual similarity and exact keyword matches.\n",
    "2. Flexibility: The `alpha` parameter allows for adjusting the balance between vector and keyword search based on specific use cases or query types.\n",
    "3. Robustness: The combined approach can handle a wider range of queries effectively, mitigating weaknesses of individual methods.\n",
    "4. Customizability: The system can be easily adapted to use different vector stores or keyword-based retrieval methods.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Fusion retrieval represents a powerful approach to document search that combines the strengths of semantic understanding and keyword matching. By leveraging both vector-based and BM25 retrieval methods, it offers a more comprehensive and flexible solution for information retrieval tasks. This approach has potential applications in various fields where both conceptual similarity and keyword relevance are important, such as academic research, legal document search, or general-purpose search engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/fusion_retrieval.svg\" alt=\"Fusion Retrieval\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Installation and Imports\n",
    "\n",
    "The cell below installs all necessary packages required to run this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\u001b[2mUsing Python 3.12.0 environment at: venvhyde\u001b[0m\n",
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Failed to read metadata for: numpy==2.4.0\n",
      "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: failed to open file `C:\\RAG\\advanced-rag-tutorials-main\\venvhyde\\Lib\\site-packages\\numpy-2.4.0.dist-info\\METADATA`: The system cannot find the file specified. (os error 2)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!uv pip install langchain langchain-openai langchain-community langchain-text-splitters faiss-cpu numpy python-dotenv rank-bm25 pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.docstore.document import Document\n",
    "\n",
    "from typing import List\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from utils.helper_functions import *\n",
    "from utils.evaluate_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define document path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the pdf to vector store and return split document from the step before to create BM25 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pdf_and_get_split_documents(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (FAISS vector store, cleaned text documents).\n",
    "    \"\"\"\n",
    "    from langchain_community.document_loaders import PyPDFLoader\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore, cleaned_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vectorstore and get the chunked documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore, cleaned_texts = encode_pdf_and_get_split_documents(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bm25 index for retrieving documents by keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.93729472 0.        ]\n",
      "['It is quite windy in London']\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "#Sparse Retrieval using BM25 sparese vectorizer and embeddings\n",
    "# Initalizing\n",
    "corpus = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\"\n",
    "]\n",
    "\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# Ranking of documents\n",
    "query = \"windy London\"\n",
    "tokenized_query = query.split(\" \")\n",
    "\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "print(doc_scores)\n",
    "\n",
    "doc_top_n = bm25.get_top_n(tokenized_query, corpus, n=1)\n",
    "print(doc_top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'there', 'good', 'man!'],\n",
       " ['It', 'is', 'quite', 'windy', 'in', 'London'],\n",
       " ['How', 'is', 'the', 'weather', 'today?']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_index(documents: List[Document]) -> BM25Okapi:\n",
    "    \"\"\"\n",
    "    Create a BM25 index from the given documents.\n",
    "\n",
    "    BM25 (Best Matching 25) is a ranking function used in information retrieval.\n",
    "    It's based on the probabilistic retrieval framework and is an improvement over TF-IDF.\n",
    "\n",
    "    Args:\n",
    "    documents (List[Document]): List of documents to index.\n",
    "\n",
    "    Returns:\n",
    "    BM25Okapi: An index that can be used for BM25 scoring.\n",
    "    \"\"\"\n",
    "    # Tokenize each document by splitting on whitespace\n",
    "    # This is a simple approach and could be improved with more sophisticated tokenization\n",
    "    tokenized_docs = [doc.page_content.split() for doc in documents]\n",
    "    return BM25Okapi(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = create_bm25_index(cleaned_texts) # Create BM25 index from the cleaned texts (chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that retrieves both semantically and by keyword, normalizes the scores and gets the top k documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_retrieval(vectorstore, bm25, query: str, k: int = 5, alpha: float = 0.5) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Perform fusion retrieval combining keyword-based (BM25) and vector-based search.\n",
    "\n",
    "    Args:\n",
    "    vectorstore (VectorStore): The vectorstore containing the documents.\n",
    "    bm25 (BM25Okapi): Pre-computed BM25 index.\n",
    "    query (str): The query string.\n",
    "    k (int): The number of documents to retrieve.\n",
    "    alpha (float): The weight for vector search scores (1-alpha will be the weight for BM25 scores).\n",
    "\n",
    "    Returns:\n",
    "    List[Document]: The top k documents based on the combined scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    epsilon = 1e-8\n",
    "\n",
    "    # Step 1: Get all documents from the vectorstore dense index\n",
    "    all_docs = vectorstore.similarity_search(\"\", k=vectorstore.index.ntotal)\n",
    "\n",
    "    # Step 2: Perform BM25 search ,it is for sparse vector scores\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "\n",
    "    # Step 3: Perform vector search\n",
    "    vector_results = vectorstore.similarity_search_with_score(query, k=len(all_docs))\n",
    "    \n",
    "    # Step 4: Normalize scores -- It is for dense vector scores we do 1 - score because lower is better\n",
    "    vector_scores = np.array([score for _, score in vector_results])\n",
    "    vector_scores = 1 - (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + epsilon)\n",
    "\n",
    "    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) -  np.min(bm25_scores) + epsilon)\n",
    "\n",
    "    # Step 5: Combine scores, alpha is the weighted of average\n",
    "    combined_scores = alpha * vector_scores + (1 - alpha) * bm25_scores  \n",
    "\n",
    "    # Step 6: Rank documents\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "    \n",
    "    # Step 7: Return top k documents\n",
    "    return [all_docs[i] for i in sorted_indices[:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "Legacy and Responsibility \n",
      "Recognizing the responsibility to future generations is a fundamental aspect of climate action. \n",
      "This involves making decisions that protect the environment and ensure a sustainable future. \n",
      "Promoting a sense of stewardship and legacy encourages long-term thinking and \n",
      "commitment. \n",
      "By continuing to innovate, collaborate, and integrate diverse perspectives, we can address the \n",
      "complex and urgent challenge of climate change. Our collective efforts will determine the \n",
      "health and sustainability of our planet for generations to come. Together, we can create a \n",
      "resilient, equitable, and thriving world.\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Vision for a Sustainable Future \n",
      "Holistic Approach \n",
      "Addressing climate change requires a holistic approach that integrates environmental, social, \n",
      "and economic dimensions. Sustainable development, circular economy, and ecological justice \n",
      "are key principles guiding this approach. Collaboration across sectors and scales is essential \n",
      "for achieving a sustainable future. \n",
      "Innovation and Creativity \n",
      "Innovation and creativity are vital for developing new solutions to climate challenges. This \n",
      "includes technological advancements, policy innovations, and creative approaches to \n",
      "education and communication. Fostering a culture of innovation supports continuous \n",
      "improvement and adaptation. \n",
      "Global Solidarity \n",
      "Global solidarity and cooperation are fundamental for addressing the global challenge of \n",
      "climate change. This includes supporting vulnerable countries and communities, sharing \n",
      "resources and technologies, and promoting equitable solutions. Solidarity strengthens global\n",
      "\n",
      "\n",
      "Context 3:\n",
      "arid and semi-arid regions. Droughts can lead to food and water shortages and exacerbate \n",
      "conflicts. \n",
      "Flooding \n",
      "Heavy rainfall events are becoming more common, leading to increased flooding. Urban \n",
      "areas with poor drainage and infrastructure are particularly at risk. Flood management \n",
      "strategies include improved drainage systems, green infrastructure, and floodplain restoration. \n",
      "Ocean Acidification \n",
      "Increased CO2 levels in the atmosphere lead to higher concentrations of CO2 in the oceans. \n",
      "This causes the water to become more acidic, which can harm marine life, particularly \n",
      "organisms with calcium carbonate shells or skeletons, such as corals and some shellfish. \n",
      "Coral Reefs\n",
      "\n",
      "\n",
      "Context 4:\n",
      "This vision includes a healthy planet, thriving ecosystems, and equitable societies. Working \n",
      "together towards this vision creates a sense of purpose and motivation. \n",
      "By embracing these principles and taking concerted action, we can address the urgent \n",
      "challenge of climate change and build a sustainable, resilient, and equitable world for all. The \n",
      "path forward requires courage, commitment, and collaboration, but the rewards are \n",
      "immenseâ€”a thriving planet and a prosperous future for generations to come. \n",
      "Chapter 13: Climate Change and Social Justice \n",
      "Climate Justice \n",
      "Understanding Climate Justice \n",
      "Climate justice emphasizes the ethical dimensions of climate change, recognizing that its \n",
      "impacts are not evenly distributed. Vulnerable populations, including low-income \n",
      "communities, indigenous peoples, and marginalized groups, often face the greatest risks \n",
      "while contributing the least to greenhouse gas emissions. Climate justice advocates for\n",
      "\n",
      "\n",
      "Context 5:\n",
      "Legacy for Future Generations \n",
      "Our actions today shape the world for future generations. Ensuring a sustainable and resilient \n",
      "planet is our responsibility to future generations. By working together, we can create a legacy \n",
      "of environmental stewardship, social equity, and global solidarity. \n",
      "Chapter 19: Climate Change and Policy \n",
      "Policy Development and Implementation \n",
      "National Climate Policies \n",
      "Countries around the world are developing and implementing national climate policies to \n",
      "address climate change. These policies set emission reduction targets, promote renewable \n",
      "energy, and support adaptation measures. Effective policy implementation requires\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query\n",
    "query = \"What are the impacts of climate change on the environment?\"\n",
    "\n",
    "# Perform fusion retrieval\n",
    "top_docs = fusion_retrieval(vectorstore, bm25, query, k=5, alpha=0.6)\n",
    "docs_content = [doc.page_content for doc in top_docs]\n",
    "show_context(docs_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The main topic of this document is environmental sustainability and climate change, including the challenges, policies, and potential solutions related to these issues.\n",
      "\n",
      "Sources:\n",
      "- challenges. This vision includes healthy ecosystems, sustainable economies, and social \n",
      "justice. Achieving this vision requires commitment, innovation, and collective effort. \n",
      "Legacy for Future Genera...\n",
      "- Direct Air Capture (DAC) \n",
      "DAC technology removes CO2 directly from the atmosphere, offering a way to achieve \n",
      "negative emissions. The captured CO2 can be stored or used in various applications. Scalin...\n",
      "- includes technological advancements, policy innovations, and creative approaches to \n",
      "education and communication. Fostering a culture of innovation supports continuous \n",
      "improvement and adaptation. \n",
      "Gl...\n",
      "- emissions, particularly methane, which is a potent greenhouse gas. Innovations in fracking \n",
      "technology have made natural gas more accessible, but this comes with environmental and \n",
      "health concerns. \n",
      "D...\n",
      "- for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate. \n",
      "Fossil Fuels \n",
      "Burning fossil fuel...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_classic.retrievers.ensemble import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(\"data/Understanding_Climate_Change.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Dense retriever (semantic)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Chroma.from_documents(splits, embeddings)\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Sparse retriever (keyword - BM25)\n",
    "sparse_retriever = BM25Retriever.from_documents(splits)\n",
    "sparse_retriever.k = 3\n",
    "\n",
    "alpha = 0.6  # Weight for dense retriever\n",
    "# Hybrid retriever\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[dense_retriever, sparse_retriever],\n",
    "    weights=[alpha, 1-alpha]\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Create RAG chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=hybrid_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Query with generation\n",
    "query = \"What is the main topic of this document?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"Answer:\", result[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, SimpleDirectoryReader, Settings\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnode_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceSplitter\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ollama\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'llama_index'"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Configure LLM and embeddings\n",
    "Settings.llm = Ollama(model=\"llama3.2\", temperature=0)\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Load PDF\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"document.pdf\"]\n",
    ").load_data()\n",
    "\n",
    "# Create index with chunking\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    node_parser=SentenceSplitter(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create query engine with hybrid retriever\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "# Query with generation\n",
    "response = query_engine.query(\"What is the main topic of this document?\")\n",
    "\n",
    "print(\"Answer:\", response.response)\n",
    "print(\"\\nSources:\")\n",
    "for node in response.source_nodes:\n",
    "    print(f\"- {node.text[:200]}...\")\n",
    "    print(f\"  Score: {node.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct ChromaDB Integration\n",
    "\n",
    "- Pinecone\n",
    "- Weviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.text_splitter'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOllama\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.text_splitter'"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(\"data/Understanding_Climate_Change.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Setup ChromaDB\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = client.get_or_create_collection(\"pdf_docs\")\n",
    "\n",
    "# Embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Add documents\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    collection.add(\n",
    "        ids=[f\"doc_{idx}\"],\n",
    "        documents=[chunk.page_content],\n",
    "        embeddings=[model.encode(chunk.page_content).tolist()],\n",
    "        metadatas=[{\"page\": chunk.metadata.get(\"page\", 0)}]\n",
    "    )\n",
    "\n",
    "# Hybrid Query\n",
    "query = \"What are the main topics?\"\n",
    "query_emb = model.encode(query)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_emb.tolist()],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "# LLM Generation\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "context = \"\\n\\n\".join(results['documents'][0])\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(\"Answer:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\u001b[2mUsing Python 3.12.0 environment at: venvhyde\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 31ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install scikit-learn sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: What is AI\n",
      "\n",
      "============================================================\n",
      "DENSE SEARCH RANKING:\n",
      "1. [0] Machine learning is a subset of artificial intelligence\n",
      "2. [4] Computer vision enables machines to interpret images\n",
      "3. [3] Natural language processing helps computers understand text\n",
      "4. [1] Deep learning uses neural networks with multiple layers\n",
      "5. [2] Python is popular for data science and ML\n",
      "\n",
      "============================================================\n",
      "SPARSE SEARCH RANKING:\n",
      "1. [0] Machine learning is a subset of artificial intelligence\n",
      "2. [2] Python is popular for data science and ML\n",
      "3. [4] Computer vision enables machines to interpret images\n",
      "4. [3] Natural language processing helps computers understand text\n",
      "5. [1] Deep learning uses neural networks with multiple layers\n",
      "\n",
      "============================================================\n",
      "HYBRID RRF RESULTS:\n",
      "============================================================\n",
      "Score: 0.049180\n",
      "Doc:   Machine learning is a subset of artificial intelligence\n",
      "\n",
      "Score: 0.048131\n",
      "Doc:   Computer vision enables machines to interpret images\n",
      "\n",
      "Score: 0.047371\n",
      "Doc:   Natural language processing helps computers understand text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def reciprocal_rank_fusion(rankings, k=60, weights=None):\n",
    "    \"\"\"RRF implementation\"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1.0] * len(rankings)\n",
    "    \n",
    "    doc_scores = {}\n",
    "    for ranking_idx, ranking in enumerate(rankings):\n",
    "        weight = weights[ranking_idx]\n",
    "        for rank_position, doc_id in enumerate(ranking, start=1):\n",
    "            rrf_score = weight * (1.0 / (k + rank_position))\n",
    "            doc_scores[doc_id] = doc_scores.get(doc_id, 0.0) + rrf_score\n",
    "    \n",
    "    return sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence\",\n",
    "    \"Deep learning uses neural networks with multiple layers\",\n",
    "    \"Python is popular for data science and ML\",\n",
    "    \"Natural language processing helps computers understand text\",\n",
    "    \"Computer vision enables machines to interpret images\"\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = \"What is AI\"\n",
    "\n",
    "# ============================================\n",
    "# DENSE SEARCH (Vector/Semantic)\n",
    "# ============================================\n",
    "dense_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = dense_model.encode(documents)\n",
    "query_embedding = dense_model.encode(query)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = np.dot(doc_embeddings, query_embedding) / (\n",
    "    np.linalg.norm(doc_embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    ")\n",
    "\n",
    "# Get ranked document IDs (by similarity)\n",
    "dense_ranking = np.argsort(similarities)[::-1].tolist()\n",
    "\n",
    "# ============================================\n",
    "# SPARSE SEARCH (Keyword/BM25-like)\n",
    "# ============================================\n",
    "tfidf = TfidfVectorizer()\n",
    "doc_tfidf = tfidf.fit_transform(documents)\n",
    "query_tfidf = tfidf.transform([query])\n",
    "\n",
    "# Calculate TF-IDF scores\n",
    "tfidf_scores = (doc_tfidf @ query_tfidf.T).toarray().flatten()\n",
    "\n",
    "# Get ranked document IDs\n",
    "sparse_ranking = np.argsort(tfidf_scores)[::-1].tolist()\n",
    "\n",
    "# ============================================\n",
    "# HYBRID SEARCH WITH RRF\n",
    "# ============================================\n",
    "hybrid_results = reciprocal_rank_fusion(\n",
    "    rankings=[dense_ranking, sparse_ranking],\n",
    "    k=60,\n",
    "    weights=[2.0, 1.0]  # Dense search more important\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# DISPLAY RESULTS\n",
    "# ============================================\n",
    "print(\"QUERY:\", query)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DENSE SEARCH RANKING:\")\n",
    "for rank, doc_idx in enumerate(dense_ranking, 1):\n",
    "    print(f\"{rank}. [{doc_idx}] {documents[doc_idx]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPARSE SEARCH RANKING:\")\n",
    "for rank, doc_idx in enumerate(sparse_ranking, 1):\n",
    "    print(f\"{rank}. [{doc_idx}] {documents[doc_idx]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HYBRID RRF RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "for doc_idx, score in hybrid_results[:3]:  # Top 3\n",
    "    print(f\"Score: {score:.6f}\")\n",
    "    print(f\"Doc:   {documents[doc_idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Dict\n",
    "\n",
    "def relative_score_fusion(\n",
    "    results: Dict[str, List[dict]],\n",
    "    weights: Dict[str, float],\n",
    "    epsilon: float = 1e-8\n",
    "):\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"dense\":  [{\"id\": \"d1\", \"score\": 0.82, \"text\": \"...\"}],\n",
    "        \"sparse\": [{\"id\": \"d1\", \"score\": 12.4, \"text\": \"...\"}]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    fused = defaultdict(lambda: {\"score\": 0.0, \"text\": None})\n",
    "\n",
    "    for name, docs in results.items():\n",
    "        scores = [d[\"score\"] for d in docs]\n",
    "        min_s, max_s = min(scores), max(scores)\n",
    "\n",
    "        for d in docs:\n",
    "            norm = (d[\"score\"] - min_s) / (max_s - min_s + epsilon)\n",
    "            fused[d[\"id\"]][\"score\"] += weights[name] * norm\n",
    "            fused[d[\"id\"]][\"text\"] = d[\"text\"]\n",
    "\n",
    "    return sorted(\n",
    "        [{\"id\": k, **v} for k, v in fused.items()],\n",
    "        key=lambda x: x[\"score\"],\n",
    "        reverse=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52375704, 0.23118885, 0.2116909 , 0.29783887, 0.3093274 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1 0.6\n",
      "doc2 0.4\n",
      "doc3 0.0\n"
     ]
    }
   ],
   "source": [
    "# **************Need to be fixed**************\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence\",\n",
    "    \"Deep learning uses neural networks with multiple layers\",\n",
    "    \"Python is popular for data science and ML\",\n",
    "    \"Natural language processing helps computers understand text\",\n",
    "    \"Computer vision enables machines to interpret images\"\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = \"What is AI\"\n",
    "\n",
    "# ============================================\n",
    "# DENSE SEARCH (Vector/Semantic)\n",
    "# ============================================\n",
    "dense_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = dense_model.encode(documents)\n",
    "query_embedding = dense_model.encode(query)\n",
    "\n",
    " vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = np.dot(doc_embeddings, query_embedding) / (\n",
    "    np.linalg.norm(doc_embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    ")\n",
    "\n",
    " # Step 1: Get all documents from the vectorstore dense index\n",
    "all_docs = vectorstore.similarity_search(\"\", k=vectorstore.index.ntotal)\n",
    " # Step 3: Perform vector search\n",
    "vector_results = vectorstore.similarity_search_with_score(query, k=len(documents))\n",
    "    \n",
    "    # Step 4: Normalize scores -- It is for dense vector scores we do 1 - score because lower is better\n",
    "vector_scores = np.array([score for _, score in vector_results])\n",
    "\n",
    "\n",
    "\n",
    "# Get ranked document IDs (by similarity)\n",
    "dense_ranking = np.argsort(similarities)[::-1].tolist()\n",
    "\n",
    "# ============================================\n",
    "# SPARSE SEARCH (Keyword/BM25-like)\n",
    "# ============================================\n",
    "tfidf = TfidfVectorizer()\n",
    "doc_tfidf = tfidf.fit_transform(documents)\n",
    "query_tfidf = tfidf.transform([query])\n",
    "\n",
    "# Calculate TF-IDF scores\n",
    "tfidf_scores = (doc_tfidf @ query_tfidf.T).toarray().flatten()\n",
    "\n",
    "dense_results = [\n",
    "    {\"id\": \"doc1\", \"score\": 0.81, \"text\": \"Hybrid search improves recall\"},\n",
    "    {\"id\": \"doc2\", \"score\": 0.74, \"text\": \"Vector databases store embeddings\"},\n",
    "]\n",
    "\n",
    "sparse_results = [\n",
    "    {\"id\": \"doc2\", \"score\": 18.3, \"text\": \"Vector databases store embeddings\"},\n",
    "    {\"id\": \"doc3\", \"score\": 12.1, \"text\": \"BM25 is lexical retrieval\"},\n",
    "]\n",
    "\n",
    "results = {\n",
    "    \"dense\": vector_scores,\n",
    "    \"sparse\": tfidf_scores\n",
    "}\n",
    "\n",
    "weights = {\n",
    "    \"dense\": 0.6,\n",
    "    \"sparse\": 0.4\n",
    "}\n",
    "\n",
    "fused = relative_score_fusion(results, weights)\n",
    "\n",
    "for d in fused:\n",
    "    print(d[\"id\"], round(d[\"score\"], 3))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venvadv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
